# IPTU Data Pipeline - Neuro Tech Challenge

Pipeline completo de processamento, validaÃ§Ã£o e anÃ¡lise de dados IPTU da cidade de Recife.

## ğŸ“‹ Ãndice

- [VisÃ£o Geral](#visÃ£o-geral)
- [Estrutura do Projeto](#estrutura-do-projeto)
- [Requisitos](#requisitos)
- [InstalaÃ§Ã£o](#instalaÃ§Ã£o)
- [Uso](#uso)
- [Funcionalidades](#funcionalidades)
- [Arquitetura](#arquitetura)
- [EntregÃ¡veis](#entregÃ¡veis)

## ğŸ¯ VisÃ£o Geral

Este projeto implementa um pipeline completo de dados para processar informaÃ§Ãµes de IPTU (Imposto Predial e Territorial Urbano) da cidade de Recife, cobrindo os anos de 2020 a 2024. O pipeline inclui:

- âœ… ValidaÃ§Ã£o de qualidade dos dados
- âœ… IngestÃ£o incremental de novos anos
- âœ… TransformaÃ§Ã£o e unificaÃ§Ã£o de schemas diferentes
- âœ… AnÃ¡lises estatÃ­sticas e de volume
- âœ… Dashboard interativo com visualizaÃ§Ãµes
- âœ… OrquestraÃ§Ã£o com Apache Airflow

## ğŸ“ Estrutura do Projeto

```
neuro_tech/
â”œâ”€â”€ data/                          # Dados de entrada
â”‚   â”œâ”€â”€ iptu_2020/
â”‚   â”œâ”€â”€ iptu_2021/
â”‚   â”œâ”€â”€ iptu_2022/
â”‚   â”œâ”€â”€ iptu_2023/
â”‚   â””â”€â”€ iptu_2024_json/
â”œâ”€â”€ src/
â”‚   â””â”€â”€ iptu_pipeline/
â”‚       â”œâ”€â”€ pipelines/
â”‚       â”‚   â”œâ”€â”€ ingestion.py      # MÃ³dulo de ingestÃ£o
â”‚       â”‚   â”œâ”€â”€ transformation.py # MÃ³dulo de transformaÃ§Ã£o
â”‚       â”‚   â”œâ”€â”€ analysis.py       # MÃ³dulo de anÃ¡lises
â”‚       â”‚   â””â”€â”€ main_pipeline.py  # Pipeline principal
â”‚       â”œâ”€â”€ utils/
â”‚       â”‚   â”œâ”€â”€ data_quality.py   # ValidaÃ§Ã£o de qualidade
â”‚       â”‚   â””â”€â”€ logger.py         # Sistema de logs
â”‚       â”œâ”€â”€ config.py             # ConfiguraÃ§Ãµes
â”‚       â”œâ”€â”€ orchestration.py      # OrquestraÃ§Ã£o Prefect
â”‚       â””â”€â”€ dashboard.py          # GeraÃ§Ã£o de dashboard
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ eda_notebook.ipynb        # AnÃ¡lise exploratÃ³ria
â”‚   â””â”€â”€ pipeline_execution.ipynb  # ExecuÃ§Ã£o do pipeline
â”œâ”€â”€ outputs/                      # SaÃ­das do pipeline
â”‚   â”œâ”€â”€ analyses/                 # Resultados das anÃ¡lises
â”‚   â”œâ”€â”€ dashboard.html            # Dashboard interativo
â”‚   â””â”€â”€ *.csv                     # RelatÃ³rios diversos
â”œâ”€â”€ logs/                         # Logs do pipeline
â”œâ”€â”€ main.py                       # Script principal
â”œâ”€â”€ pyproject.toml                # DependÃªncias
â”œâ”€â”€ ARCHITECTURE.md               # Diagrama de arquitetura
â””â”€â”€ README.md                     # Este arquivo
```

## ğŸ”§ Requisitos

- Python 3.11 ou superior
- uv (gerenciador de pacotes) - opcional, pode usar pip/conda

### Engines Suportados

O pipeline suporta dois engines de processamento:
- **Pandas** (padrÃ£o) - Para datasets atÃ© ~50 GB
- **PySpark** (opcional) - Para datasets grandes e processamento distribuÃ­do

Consulte `README_ENGINE.md` para detalhes sobre escolha e configuraÃ§Ã£o do engine.

## ğŸ“¦ InstalaÃ§Ã£o

1. Clone o repositÃ³rio ou navegue atÃ© o diretÃ³rio do projeto

2. Instale as dependÃªncias:

```bash
# Com uv
uv sync

# Ou com pip
pip install -e .
```

## ğŸš€ Uso

### ExecuÃ§Ã£o Completa do Pipeline

**OpÃ§Ã£o 1: Local com Pandas (padrÃ£o)**
```bash
python main.py
```

**OpÃ§Ã£o 2: Local com PySpark**
```bash
export IPTU_DATA_ENGINE=pyspark  # Windows: $env:IPTU_DATA_ENGINE="pyspark"
python main.py
```

**OpÃ§Ã£o 3: Docker com Spark (Recomendado para demonstraÃ§Ã£o)**
```bash
# Standalone mode (mais simples)
docker-compose -f docker-compose.standalone.yml up --build

# Ou usando script
# Windows PowerShell
.\docker-run.ps1

# Linux/Mac
chmod +x docker-run.sh && ./docker-run.sh
```

**Acesso ao Spark UI:** http://localhost:4040

Para mais detalhes sobre Docker, veja [DOCKER_SETUP.md](DOCKER_SETUP.md)

Ou atravÃ©s do Python:

```python
from iptu_pipeline.orchestration import run_orchestrated_pipeline

# Executar pipeline completo
consolidated_df = run_orchestrated_pipeline(
    years=None,  # None = todos os anos
    incremental=False,
    run_analysis=True
)
```

### ExecuÃ§Ã£o Incremental (Novos Anos)

Para adicionar apenas novos anos sem reprocessar tudo:

```python
from iptu_pipeline.orchestration import run_orchestrated_pipeline

# Apenas ano 2024 (exemplo)
consolidated_df = run_orchestrated_pipeline(
    years=[2024],
    incremental=True,  # Modo incremental
    run_analysis=True
)
```

### GeraÃ§Ã£o de Dashboard

```python
from iptu_pipeline.dashboard import IPTUDashboard
import pandas as pd
from iptu_pipeline.config import CONSOLIDATED_DATA_PATH

# Carregar dados consolidados
df = pd.read_parquet(CONSOLIDATED_DATA_PATH)

# Criar e gerar dashboard
dashboard = IPTUDashboard(df=df)
dashboard.generate_dashboard_html()  # Gera outputs/dashboard.html
dashboard.generate_summary_report()  # Gera outputs/summary_report.txt
```

### Notebooks Jupyter

Execute os notebooks em `notebooks/` para:
- AnÃ¡lise exploratÃ³ria inicial (`eda_notebook.ipynb`)
- ExecuÃ§Ã£o do pipeline (`pipeline_execution.ipynb`)

## âœ¨ Funcionalidades

### 1. Qualidade dos Dados

O mÃ³dulo `DataQualityValidator` implementa validaÃ§Ãµes robustas:

- âœ… ValidaÃ§Ã£o de estrutura (linhas, colunas)
- âœ… VerificaÃ§Ã£o de valores nulos (% de threshold)
- âœ… DetecÃ§Ã£o de duplicatas
- âœ… ValidaÃ§Ã£o de tipos de dados
- âœ… Regras de negÃ³cio (CEP, cidade, estado)
- âœ… GeraÃ§Ã£o de relatÃ³rios detalhados

**SaÃ­das:**
- `outputs/validation_report.csv`: Resumo das validaÃ§Ãµes por ano
- `outputs/validation_errors.csv`: Tabela detalhada de erros e warnings

### 2. IngestÃ£o Incremental

O mÃ³dulo `DataIngestion` suporta:

- âœ… Carregamento de CSV (2020-2023) e JSON (2024)
- âœ… ValidaÃ§Ã£o automÃ¡tica durante ingestÃ£o
- âœ… Modo incremental: processa apenas anos novos
- âœ… Status de ingestÃ£o por ano

**BenefÃ­cios:**
- Adiciona novos anos sem reprocessar toda a base
- MantÃ©m histÃ³rico preservado
- Eficiente em termos de processamento

### 3. Tratamento e UnificaÃ§Ã£o

O mÃ³dulo `DataTransformer`:

- âœ… Normaliza diferenÃ§as de schema entre anos
- âœ… Trata coluna `_id` do ano 2024
- âœ… Padroniza nomes de colunas
- âœ… Adiciona colunas faltantes com valores nulos
- âœ… Padroniza tipos de dados
- âœ… Otimiza uso de memÃ³ria (categorias, downcast)
- âœ… Consolida todos os anos em um dataset unificado

**Resultado:** Dataset unificado pronto para anÃ¡lise

### 4. AnÃ¡lises

O mÃ³dulo `IPTUAnalyzer` realiza:

#### AnÃ¡lises ObrigatÃ³rias:

1. **Volume Total:**
   - Total de imÃ³veis
   - DistribuiÃ§Ã£o por ano (histÃ³rico)
   - DistribuiÃ§Ã£o por tipo de uso
   - DistribuiÃ§Ã£o por bairro
   - Volume por ano E tipo (cruzamento)
   - Volume por ano E bairro (cruzamento)

2. **DistribuiÃ§Ã£o FÃ­sica:**
   - Por tipo de uso (histÃ³rico)
   - Por bairro (histÃ³rico e top 20)
   - Por ano (distribuiÃ§Ã£o temporal)
   - Top bairros por ano

#### AnÃ¡lise Adicional:

3. **TendÃªncias de Valores de IPTU:**
   - EstatÃ­sticas de IPTU por ano (mÃ©dia, mediana, min, max)
   - Bairros com maiores valores mÃ©dios de IPTU
   - AnÃ¡lise de valor total dos imÃ³veis por ano

**SaÃ­das:** CSV em `outputs/analyses/` organizados por tipo de anÃ¡lise

### 5. OrquestraÃ§Ã£o

OrquestraÃ§Ã£o implementada com **Apache Airflow**:

- âœ… DAG com tasks separadas para cada etapa
- âœ… Retry automÃ¡tico configurÃ¡vel
- âœ… Logging integrado por task
- âœ… DependÃªncias claras entre tasks
- âœ… ExecuÃ§Ã£o paralela de validaÃ§Ãµes
- âœ… Agendamento flexÃ­vel

**Fluxo de Tasks:**
1. `validate_data_quality_2020-2024` (paralelas)
2. `ingest_data`
3. `transform_and_consolidate`
4. `save_consolidated_data`
5. `run_analysis`
6. `generate_dashboard`
7. `generate_reports`

Consulte `AIRFLOW_SETUP.md` para instruÃ§Ãµes de configuraÃ§Ã£o e uso.

### 6. VisualizaÃ§Ãµes e GrÃ¡ficos

GrÃ¡ficos estÃ¡ticos gerados com **Matplotlib e Seaborn**:

- âœ… Volume de imÃ³veis por ano (grÃ¡fico de barras)
- âœ… DistribuiÃ§Ã£o por tipo de uso (pizza e barras)
- âœ… Top bairros por volume (grÃ¡fico horizontal)
- âœ… EvoluÃ§Ã£o por ano e tipo (Ã¡rea empilhada)
- âœ… TendÃªncias de valores de IPTU (linha e barras)
- âœ… Top bairros por valor de IPTU (grÃ¡fico horizontal)
- âœ… DistribuiÃ§Ã£o por tipo de construÃ§Ã£o
- âœ… DistribuiÃ§Ã£o temporal (linha)

**SaÃ­das:**
- GrÃ¡ficos PNG em alta resoluÃ§Ã£o (`outputs/plots/`)
- RelatÃ³rio HTML com todos os grÃ¡ficos (`outputs/plots/visualizations_report.html`)

Para gerar os grÃ¡ficos:
```python
from iptu_pipeline.visualizations import generate_plots_from_analysis_results

plot_files = generate_plots_from_analysis_results()
```

Ou execute o script:
```bash
python scripts/generate_plots.py
```

### 7. Dashboard e RelatÃ³rios

Dashboard interativo gerado com **Plotly**:

- âœ… GrÃ¡ficos de volume por ano
- âœ… DistribuiÃ§Ã£o por tipo (pie chart)
- âœ… Top bairros (bar charts)
- âœ… Heatmaps de distribuiÃ§Ã£o
- âœ… TendÃªncias de valores de IPTU
- âœ… ExportaÃ§Ã£o para HTML interativo

**SaÃ­das:**
- `outputs/dashboard.html`: Dashboard completo interativo
- `outputs/summary_report.txt`: RelatÃ³rio textual resumido

## ğŸ—ï¸ Arquitetura

Consulte `ARCHITECTURE.md` para:
- Diagrama completo da arquitetura
- Fluxo de dados detalhado
- DecisÃµes de design
- Tecnologias utilizadas

### Resumo da Arquitetura

```
Dados â†’ IngestÃ£o â†’ ValidaÃ§Ã£o â†’ TransformaÃ§Ã£o â†’ Armazenamento â†’ AnÃ¡lise â†’ Dashboard
```

## ğŸ“Š EntregÃ¡veis

### 1. âœ… CÃ³digo Desenvolvido

- Pipeline modular em Python
- Notebooks Jupyter para exploraÃ§Ã£o e execuÃ§Ã£o
- Scripts de orquestraÃ§Ã£o

### 2. âœ… Diagrama de Arquitetura

- Arquivo `ARCHITECTURE.md` com:
  - Diagrama ASCII da arquitetura
  - Fluxo de dados detalhado
  - Tecnologias e decisÃµes

### 3. âœ… RepositÃ³rio Git

- Estrutura organizada
- CÃ³digo modular
- DocumentaÃ§Ã£o completa

### 4. âœ… Dashboard/RelatÃ³rio

- Dashboard HTML interativo (`outputs/dashboard.html`)
- RelatÃ³rio textual (`outputs/summary_report.txt`)
- AnÃ¡lises em CSV (`outputs/analyses/`)

### 5. âœ… Materiais de Apoio

- ValidaÃ§Ãµes detalhadas (`outputs/validation_*.csv`)
- Notebooks de exploraÃ§Ã£o
- Logs estruturados (`logs/`)

## ğŸ“ˆ Resultados das AnÃ¡lises

ApÃ³s executar o pipeline, as anÃ¡lises respondem:

1. **Volume Total:** Total de imÃ³veis e distribuiÃ§Ã£o por tipo/bairro
2. **HistÃ³rico:** EvoluÃ§Ã£o ano a ano
3. **DistribuiÃ§Ã£o FÃ­sica:** Top bairros, tipos de uso mais comuns
4. **TendÃªncias:** Valores de IPTU ao longo do tempo (anÃ¡lise adicional)

## ğŸ” Logs

Todos os logs sÃ£o salvos em `logs/` com formato estruturado:
- Data e hora
- NÃ­vel de log
- MÃ³dulo origem
- Mensagem detalhada

## ğŸ“ Notas

- O pipeline suporta adiÃ§Ã£o de novos anos sem reprocessar toda a base
- ValidaÃ§Ãµes sÃ£o registradas em arquivos CSV para auditoria
- Dashboard Ã© gerado automaticamente apÃ³s anÃ¡lises
- Airflow Ã© opcional (pipeline funciona em modo direto sem Airflow)

## ğŸš§ PrÃ³ximos Passos (Melhorias Futuras)

- [ ] Testes unitÃ¡rios automatizados
- [ ] CI/CD pipeline
- [ ] Deploy do dashboard em servidor web
- [ ] IntegraÃ§Ã£o com banco de dados
- [ ] Agendamento automÃ¡tico com Prefect Cloud
- [ ] Alertas de qualidade de dados

## ğŸ“„ LicenÃ§a

Este projeto foi desenvolvido para o desafio tÃ©cnico da Neuro Tech.

