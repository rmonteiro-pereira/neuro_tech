# IPTU Data Pipeline - Neuro Tech Challenge

> **A comprehensive, production-ready data pipeline for IPTU (Property Tax) data processing, featuring a medallion architecture with PySpark support, data quality validation, and automated analytics.**

[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![Apache Spark](https://img.shields.io/badge/Apache%20Spark-3.4+-orange.svg)](https://spark.apache.org/)
[![Delta Lake](https://img.shields.io/badge/Delta%20Lake-3.3+-0078D4.svg)](https://delta.io/)
[![PyDeequ](https://img.shields.io/badge/PyDeequ-1.5+-red.svg)](https://github.com/pydeequ/pydeequ)

---

## Table of Contents

- [ğŸ¯ Overview](#ğŸ¯-overview)
  - [ğŸ“Š Principais Descobertas](#ğŸ“Š-principais-descobertas)
- [âœ¨ Key Features](#âœ¨-key-features)
  - [ğŸ† Core Capabilities](#ğŸ†-core-capabilities)
  - [ğŸ”¬ Data Quality Framework](#ğŸ”¬-data-quality-framework)
- [ğŸ—ï¸ Architecture](#ğŸ—ï¸-architecture)
  - [Medallion Architecture (Delta Lake)](#medallion-architecture-delta-lake)
  - [Processing Pipeline](#processing-pipeline)
- [ğŸ“ Project Structure](#ğŸ“-project-structure)
- [ğŸš€ Installation](#ğŸš€-installation)
  - [Prerequisites](#prerequisites)
  - [Step 1: Clone Repository](#step-1-clone-repository)
  - [Step 2: Install Dependencies](#step-2-install-dependencies)
  - [Step 3: Verify Installation](#step-3-verify-installation)
- [ğŸ® Quick Start](#ğŸ®-quick-start)
  - [Run Full Pipeline (Pandas)](#run-full-pipeline-pandas)
  - [Run Full Pipeline (PySpark)](#run-full-pipeline-pyspark)
  - [Run with Docker (Spark Standalone)](#run-with-docker-spark-standalone)
- [ğŸ“– Usage Guide](#ğŸ“–-usage-guide)
  - [Basic Usage](#basic-usage)
  - [Advanced Usage](#advanced-usage)
- [âš™ï¸ Configuration](#âš™ï¸-configuration)
  - [Environment Variables](#environment-variables)
  - [Configuration File](#configuration-file)
  - [Spark Configuration](#spark-configuration)
- [ğŸ” Data Quality](#ğŸ”-data-quality)
  - [Validation Framework](#validation-framework)
  - [Quality Reports](#quality-reports)
  - [Running Quality Checks](#running-quality-checks)
- [ğŸ“Š Analytics & Visualizations](#ğŸ“Š-analytics--visualizations)
  - [ğŸ“ˆ AnÃ¡lises e Respostas Ã s Perguntas Principais](#ğŸ“ˆ-anÃ¡lises-e-respostas-Ã s-perguntas-principais)
  - [ğŸ“Š Todas as VisualizaÃ§Ãµes DisponÃ­veis](#ğŸ“Š-todas-as-visualizaÃ§Ãµes-disponÃ­veis)
  - [ğŸ“‚ Estrutura Completa das AnÃ¡lises](#ğŸ“‚-estrutura-completa-das-anÃ¡lises)
- [ğŸ“¤ Outputs](#ğŸ“¤-outputs)
  - [Medallion Layers](#medallion-layers)
  - [Analysis Results](#analysis-results)
  - [Visualizations](#visualizations)
  - [Legacy Outputs](#legacy-outputs)
  - [Catalog](#catalog)
- [ğŸ”¬ Advanced Features](#ğŸ”¬-advanced-features)
  - [Delta Lake Features](#delta-lake-features)
  - [PyDeequ Integration](#pydeequ-integration)
  - [Catalog System](#catalog-system)
  - [Incremental Processing](#incremental-processing)
  - [Export Script](#export-script)
- [ğŸ¯ Next Steps](#ğŸ¯-next-steps)

---

## ğŸ¯ Overview

This project implements an enterprise-grade data pipeline for processing IPTU (Imposto Predial e Territorial Urbano) tax data from Recife, Brazil, covering years 2020-2024. Built on Python 3.11+, it features:

- **Medallion Architecture**: Raw â†’ Bronze â†’ Silver â†’ Gold data layers
- **Dual Engine Support**: Pandas (default) and PySpark (distributed processing)
- **Data Quality Framework**: Automated validation with PyDeequ
- **Delta Lake Integration**: ACID transactions and schema evolution
- **Comprehensive Analytics**: Volume, distribution, age, value, and evolution analysis
- **Interactive Dashboards**: Plotly-powered visualizations
- **Orchestration**: Apache Airflow DAGs for automated workflows

### ğŸ“Š Principais Descobertas

O pipeline processou e analisou **1.637.779 imÃ³veis** do IPTU de Recife:

- **Volume**: DistribuiÃ§Ã£o completa por tipo de uso, bairro, e ano (2020-2024)
- **Idade**: InventÃ¡rio predominantemente de meia-idade (21-50 anos de construÃ§Ã£o)
- **Valor**: DOIS IRMAOS, MONTEIRO e GUABIRABA sÃ£o os bairros com maior valor mÃ©dio de IPTU
- **EvoluÃ§Ã£o**: AnÃ¡lise detalhada da evoluÃ§Ã£o de bairros em quantidade e valor

Todas as anÃ¡lises estÃ£o disponÃ­veis em `data/gold/analyses/` e visualizaÃ§Ãµes em `data/gold/plots/`.

---

## âœ¨ Key Features

### ğŸ† Core Capabilities

| Feature | Description | Status |
|---------|-------------|--------|
| **Multi-Format Support** | CSV (2020-2023) and JSON (2024) | âœ… |
| **Schema Evolution** | Automatic handling of schema changes between years | âœ… |
| **Incremental Processing** | Add new years without reprocessing entire dataset | âœ… |
| **Data Quality Checks** | 7-layer validation with PyDeequ integration | âœ… |
| **Medallion Architecture** | Raw â†’ Bronze â†’ Silver â†’ Gold layers | âœ… |
| **Delta Lake** | ACID transactions, time travel, column mapping | âœ… |
| **Distributed Processing** | PySpark with Spark 3.4+ support | âœ… |
| **Automated Analytics** | Volume, distribution, and trend analysis | âœ… |
| **Interactive Dashboards** | Plotly and Matplotlib visualizations | âœ… |
| **Orchestration** | Apache Airflow DAG integration | âœ… |
| **Catalog System** | Centralized metadata tracking | âœ… |
| **Docker Support** | Containerized Spark environment | âœ… |

### ğŸ”¬ Data Quality Framework

- **PyDeequ Integration**: AWS Deequ automated data quality checks
- **Multi-Layer Validation**: Structure, completeness, uniqueness, business rules
- **Automated Reports**: JSON and CSV validation reports
- **Column Profiling**: Statistical analysis per column
- **Anomaly Detection**: Automated detection of data quality issues
- **Error Tracking**: Comprehensive error and warning logs

---

## ğŸ—ï¸ Architecture

### Medallion Architecture (Delta Lake)

The pipeline follows a **medallion architecture** with four data layers:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     RAW LAYER (data/raw/)                      â”‚
â”‚  â€¢ Source CSV/JSON files                                        â”‚
â”‚  â€¢ No processing applied                                        â”‚
â”‚  â€¢ Immutable source of truth                                    â”‚
â”‚  â€¢ Cataloged with metadata (MD5, size, discovery date)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   BRONZE LAYER (data/bronze/)                  â”‚
â”‚  â€¢ Cleaned and cataloged data                                   â”‚
â”‚  â€¢ Normalized column names                                      â”‚
â”‚  â€¢ Standardized data types                                      â”‚
â”‚  â€¢ String trimming and categorical optimization                 â”‚
â”‚  â€¢ Partitioned by year                                          â”‚
â”‚  â€¢ Delta/Parquet format                                         â”‚
â”‚  â€¢ PyDeequ quality checks                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   SILVER LAYER (data/silver/)                  â”‚
â”‚  â€¢ Consolidated multi-year dataset                              â”‚
â”‚  â€¢ Unified schema across all years                              â”‚
â”‚  â€¢ Time-series data ready for analytics                         â”‚
â”‚  â€¢ Deduplication applied                                        â”‚
â”‚  â€¢ Delta/Parquet format                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    GOLD LAYER (data/gold/)                      â”‚
â”‚  â€¢ Business-ready analytics                                     â”‚
â”‚  â€¢ Volume analysis (total, by type, by neighborhood)            â”‚
â”‚  â€¢ Age distribution analysis (construction age)                 â”‚
â”‚  â€¢ Tax value analysis (by neighborhood, trends)                 â”‚
â”‚  â€¢ Age-value relationship analysis                              â”‚
â”‚  â€¢ Neighborhood evolution analysis                              â”‚
â”‚  â€¢ Analysis results (CSV)                                       â”‚
â”‚  â€¢ Visualizations (PNG, HTML) - 8 plots + HTML report           â”‚
â”‚  â€¢ Dashboard reports                                            â”‚
â”‚  â€¢ Year-over-year trends                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Processing Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SOURCE  â”‚  â†’   â”‚  INGESTION   â”‚  â†’   â”‚  VALIDATION  â”‚  â†’   â”‚  TRANSFORM   â”‚
â”‚  FILES   â”‚      â”‚   (Raw)      â”‚      â”‚  (Bronze)    â”‚      â”‚  (Silver)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚EXPORT FORâ”‚  â†   â”‚ DASHBOARD    â”‚  â†   â”‚  ANALYSIS    â”‚  â†   â”‚  CONSOLIDATE â”‚
â”‚SHARING   â”‚      â”‚  (Gold)      â”‚      â”‚   (Gold)     â”‚      â”‚   (Silver)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Project Structure

```
neuro_tech/
â”œâ”€â”€ data/                                    # Data directory (gitignored)
â”‚   â”œâ”€â”€ raw/                                 # Raw layer: source files
â”‚   â”‚   â”œâ”€â”€ iptu_2020/iptu_2020.csv
â”‚   â”‚   â”œâ”€â”€ iptu_2021/iptu_2021.csv
â”‚   â”‚   â”œâ”€â”€ iptu_2022/iptu_2022.csv
â”‚   â”‚   â”œâ”€â”€ iptu_2023/iptu_2023.csv
â”‚   â”‚   â””â”€â”€ iptu_2024_json/iptu_2024_json.json
â”‚   â”œâ”€â”€ bronze/                              # Bronze layer: cleaned data
â”‚   â”‚   â”œâ”€â”€ iptu_2020/                       # Delta/Parquet, partitioned
â”‚   â”‚   â”œâ”€â”€ iptu_2021/
â”‚   â”‚   â”œâ”€â”€ iptu_2022/
â”‚   â”‚   â”œâ”€â”€ iptu_2023/
â”‚   â”‚   â””â”€â”€ iptu_2024/
â”‚   â”œâ”€â”€ silver/                              # Silver layer: consolidated
â”‚   â”‚   â””â”€â”€ iptu_silver_consolidated/        # Delta/Parquet
â”‚   â”œâ”€â”€ gold/                                # Gold layer: analytics
â”‚   â”‚   â”œâ”€â”€ analyses/                        # Analysis results (CSV)
â”‚   â”‚   â”œâ”€â”€ plots/                           # Visualizations (PNG, HTML)
â”‚   â”‚   â”œâ”€â”€ gold_summary_by_neighborhood/    # Aggregations
â”‚   â”‚   â”œâ”€â”€ gold_summary_by_year_type/
â”‚   â”‚   â””â”€â”€ gold_year_over_year_trends/
â”‚   â””â”€â”€ catalog/                             # Central catalog
â”‚       â”œâ”€â”€ data_catalog.json                # Human-readable catalog
â”‚       â”œâ”€â”€ data_catalog.parquet             # Queryable catalog
â”‚       â””â”€â”€ data_catalog_delta/              # Delta catalog table
â”‚
â”œâ”€â”€ src/iptu_pipeline/                       # Main source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                            # Configuration management
â”‚   â”œâ”€â”€ engine.py                            # DataEngine abstraction
â”‚   â”œâ”€â”€ dashboard.py                         # Dashboard generation
â”‚   â”œâ”€â”€ visualizations.py                    # Plot generation
â”‚   â”œâ”€â”€ orchestration.py                     # Prefect orchestration
â”‚   â”œâ”€â”€ airflow_dag.py                       # Airflow DAG
â”‚   â”‚
â”‚   â”œâ”€â”€ pipelines/                           # Pipeline modules
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ main_pipeline.py                 # Main orchestration
â”‚   â”‚   â”œâ”€â”€ ingestion.py                     # Data ingestion
â”‚   â”‚   â”œâ”€â”€ transformation.py                # Data transformation
â”‚   â”‚   â””â”€â”€ analysis.py                      # Data analysis
â”‚   â”‚
â”‚   â””â”€â”€ utils/                               # Utilities
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ logger.py                        # Logging system
â”‚       â”œâ”€â”€ data_quality.py                  # Basic validation
â”‚       â”œâ”€â”€ medallion_quality.py             # PyDeequ validation
â”‚       â”œâ”€â”€ raw_catalog.py                   # Catalog system
â”‚       â””â”€â”€ column_matcher.py                # Schema matching
â”‚
â”œâ”€â”€ scripts/                                 # Utility scripts
â”‚   â””â”€â”€ generate_plots.py                    # Standalone plot generator
â”‚
â”œâ”€â”€ notebooks/                               # Jupyter notebooks
â”‚   â”œâ”€â”€ pipeline_execution.ipynb            # Pipeline walkthrough
â”‚   â””â”€â”€ visualizations.ipynb                # Visualization exploration
â”‚
â”œâ”€â”€ dags/                                    # Airflow DAGs
â”‚   â””â”€â”€ iptu_pipeline_dag.py                # Deployable DAG
â”‚
â”œâ”€â”€ outputs/                                 # Legacy outputs
â”‚   â”œâ”€â”€ validation_report.csv
â”‚   â”œâ”€â”€ validation_errors.csv
â”‚   â””â”€â”€ medallion_validation_report.json
â”‚
â”œâ”€â”€ logs/                                    # Application logs
â”‚
â”œâ”€â”€ docker-compose.yml                       # Spark cluster setup
â”œâ”€â”€ docker-compose.standalone.yml            # Standalone Spark
â”‚
â”œâ”€â”€ main.py                                  # Entry point
â”œâ”€â”€ export_refined_dataset.py               # Export script
â”œâ”€â”€ test_pydeequ.py                         # PyDeequ tests
â”œâ”€â”€ test_delta.py                           # Delta Lake tests
â”‚
â”œâ”€â”€ pyproject.toml                          # Project metadata
â”œâ”€â”€ requirements-pyspark.txt                # PySpark dependencies
â”œâ”€â”€ requirements.txt                        # Base dependencies
â”‚
â”œâ”€â”€ README.md                               # This file
â”œâ”€â”€ ARCHITECTURE.md                         # Architecture details
â”œâ”€â”€ DOCKER_SETUP.md                         # Docker guide
â””â”€â”€ .gitignore
```

---

## ğŸš€ Installation

### Prerequisites

- **Python**: 3.11 or higher
- **Java** (for PySpark): 8 or 11
- **uv** (recommended) or pip/conda
- **Docker** (optional, for Spark)

### Step 1: Clone Repository

```bash
git clone <repository-url>
cd neuro_tech
```

### Step 2: Install Dependencies

**Option A: Using uv (Recommended)**

```bash
# Install uv if not already installed
curl -LsSf https://astral.sh/uv/install.sh | sh

# Install base dependencies
uv sync

# Install PySpark dependencies (optional, for distributed processing)
uv sync --extra pyspark
```

**Option B: Using pip**

```bash
# Create virtual environment
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate

# Install base dependencies
pip install -e .

# Install PySpark dependencies (optional)
pip install -r requirements-pyspark.txt
```

**Option C: Using conda**

```bash
# Create conda environment
conda create -n neuro-tech python=3.11
conda activate neuro-tech

# Install dependencies
pip install -e .
pip install -r requirements-pyspark.txt
```

### Step 3: Verify Installation

```bash
python -c "from iptu_pipeline import config; print(f'Engine: {config.settings.DATA_ENGINE}')"
```

Expected output: `Engine: pandas`

---

## ğŸ® Quick Start

### Run Full Pipeline (Pandas)

```bash
python main.py
```

This will:
1. Load data from `data/raw/`
2. Catalog files in `data/catalog/`
3. Process through Bronze â†’ Silver â†’ Gold layers
4. Generate analyses and visualizations
5. Save outputs to `data/gold/`

### Run Full Pipeline (PySpark)

```bash
# Windows PowerShell
$env:IPTU_DATA_ENGINE="pyspark"
python main.py

# Linux/Mac
export IPTU_DATA_ENGINE=pyspark
python main.py
```

**Example Output:**

```text
INFO - Starting IPTU Data Pipeline
INFO - Running pipeline (direct execution mode)
INFO - Local mode optimized: 16 cores, 32 shuffle partitions, 4g driver memory
INFO - Delta Lake + PyDeequ configured: JARs loaded + extensions set
INFO - Creating Spark session...
INFO - [OK] Raw files cataloged: 5 files
INFO - [BRONZE LAYER] Cleaning and Cataloging Raw Data
INFO - Processing year 2020 to bronze layer
INFO - [OK] Loaded 2020: 403,915 rows, 32 columns
INFO - [PASS] Validation PASSED for year 2020
INFO - [OK] Year 2020 saved to bronze layer
...
INFO - [SILVER LAYER] Consolidating Bronze Data
INFO - Consolidated 1,637,779 rows from 5 years
INFO - [OK] Silver layer saved: 1,637,779 rows, 37 columns
...
INFO - [GOLD LAYER] Generating Analytics and Visualizations
INFO - [OK] Generated 12 plots
INFO - [OK] HTML report created: data/gold/plots/visualizations_report.html
```

> ğŸ“ **Full Output**: See [`example_run.txt`](example_run.txt) for the complete execution log with detailed processing steps.

### Run with Docker (Spark Standalone)

```bash
# Using standalone Spark (simplest)
docker-compose -f docker-compose.standalone.yml up --build

# Using Spark cluster
docker-compose up --build
```

Access Spark UI: http://localhost:4040

---

## ğŸ“– Usage Guide

### Basic Usage

#### 1. Process All Years

```python
from iptu_pipeline.pipelines.main_pipeline import IPTUPipeline

pipeline = IPTUPipeline(engine='pandas')  # or 'pyspark'
consolidated_df = pipeline.run_full_pipeline(
    years=None,              # None = all years
    save_consolidated=True,
    run_analysis=True,
    incremental=False
)
```

#### 2. Process Specific Years

```python
pipeline = IPTUPipeline(engine='pyspark')
consolidated_df = pipeline.run_full_pipeline(
    years=[2020, 2021, 2022],
    save_consolidated=True,
    run_analysis=True,
    incremental=False
)
```

#### 3. Incremental Processing (Add New Years)

```python
# First run: process 2020-2023
pipeline.run_full_pipeline(years=[2020, 2021, 2022, 2023], incremental=False)

# Later: add 2024 without reprocessing previous years
pipeline.run_full_pipeline(years=[2024], incremental=True)
```

#### 4. Generate Visualizations

```python
from iptu_pipeline.visualizations import generate_plots_from_analysis_results

# Generate all plots
plot_files = generate_plots_from_analysis_results()
print(plot_files)
```

#### 5. Create Dashboard

```python
from iptu_pipeline.dashboard import IPTUDashboard
from iptu_pipeline.config import SILVER_DIR
from iptu_pipeline.engine import get_engine

# Load silver layer data
engine = get_engine()
if engine.engine_type == "pyspark":
    df = engine.read_parquet(SILVER_DIR / "iptu_silver_consolidated")
    df = engine.to_pandas(df)
else:
    import pandas as pd
    df = pd.read_parquet(SILVER_DIR / "iptu_silver_consolidated/data.parquet")

# Generate dashboard
dashboard = IPTUDashboard(df=df)
dashboard.generate_dashboard()
dashboard.generate_summary_report()
```

### Advanced Usage

#### Export Refined Dataset

```bash
python export_refined_dataset.py --output iptu_refined.parquet --engine pyspark
```

This creates a single Parquet file for sharing, with:
- Duplicates removed
- Metadata columns filtered
- Compatible timestamp formats
- All years consolidated

#### Run Airflow DAG

```bash
# Start Airflow (see AIRFLOW_SETUP.md)
airflow webserver --port 8080
airflow scheduler

# Trigger DAG
airflow dags trigger iptu_medallion_pipeline
```

#### Custom Configuration

```python
from iptu_pipeline.config import settings

# Modify settings
settings.DATA_ENGINE = "pyspark"
settings.MIN_ROWS_PER_YEAR = 500
settings.MAX_NULL_PERCENTAGE = 40.0

# Run pipeline with custom settings
pipeline = IPTUPipeline(engine='pyspark')
pipeline.run_full_pipeline()
```

---

## âš™ï¸ Configuration

### Environment Variables

The pipeline uses `pydantic-settings` for configuration. Set environment variables with prefix `IPTU_`:

```bash
# Windows PowerShell
$env:IPTU_DATA_ENGINE="pyspark"
$env:IPTU_MIN_ROWS_PER_YEAR="500"

# Linux/Mac
export IPTU_DATA_ENGINE=pyspark
export IPTU_MIN_ROWS_PER_YEAR=500
```

### Configuration File

Edit `src/iptu_pipeline/config.py`:

```python
class Settings(BaseSettings):
    # Base directories
    BASE_DIR: Path = ...
    DATA_DIR: Path = ...
    OUTPUT_DIR: Path = ...
    
    # Medallion layers
    RAW_DIR: Path = ...
    BRONZE_DIR: Path = ...
    SILVER_DIR: Path = ...
    GOLD_DIR: Path = ...
    CATALOG_DIR: Path = ...
    
    # Data years
    CSV_YEARS: List[int] = [2020, 2021, 2022, 2023]
    JSON_YEARS: List[int] = [2024]
    
    # Quality thresholds
    MIN_ROWS_PER_YEAR: int = 100
    MAX_NULL_PERCENTAGE: float = 50.0
    
    # Processing engine
    DATA_ENGINE: str = "pandas"  # or "pyspark"
```

### Spark Configuration

For PySpark, customize in `src/iptu_pipeline/engine.py`:

```python
builder = SparkSession.builder \
    .appName("IPTU_Pipeline") \
    .config("spark.driver.memory", "16g") \
    .config("spark.executor.memory", "16g") \
    .config("spark.sql.shuffle.partitions", "200")
```

---

## ğŸ” Data Quality

### Validation Framework

The pipeline implements **multi-layer data quality validation**:

#### Layer 1: Basic Validation (Bronze)
- Structure checks (row count, column count)
- Data type validation
- Null value percentage
- Duplicate detection
- Business rules (CEP, city, state)

#### Layer 2: PyDeequ Validation
- **Completeness**: Check for null values
- **Unique values**: Detect duplicates
- **Uniqueness**: Primary key constraints
- **Range checks**: Value constraints
- **Column profiling**: Statistical analysis
- **Anomaly detection**: Automated issue detection

#### Layer 3: Medallion Validation (Silver/Gold)
- Year consistency across layers
- Schema evolution compatibility
- Deduplication verification
- Aggregation accuracy

### Quality Reports

Reports are generated at multiple stages:

1. **data/catalog/data_catalog.json**: Raw file catalog
2. **outputs/validation_report.csv**: Per-year validation summary
3. **outputs/validation_errors.csv**: Detailed errors/warnings
4. **outputs/medallion_validation_report.json**: Layer-wise validation

### Running Quality Checks

```python
from iptu_pipeline.utils.medallion_quality import MedallionDataQuality
from iptu_pipeline.engine import get_engine

engine = get_engine('pyspark')
quality = MedallionDataQuality(engine.spark)

# Validate bronze layer
df_bronze = engine.read_parquet(BRONZE_DIR / "iptu_2020")
results = quality.validate_bronze_layer(df_bronze, year=2020)

# Validate silver layer
df_silver = engine.read_parquet(SILVER_DIR / "iptu_silver_consolidated")
results = quality.validate_silver_layer(df_silver, year=None)
```

---

## ğŸ“Š Analytics & Visualizations

Este pipeline gera anÃ¡lises abrangentes e visualizaÃ§Ãµes automÃ¡ticas sobre o inventÃ¡rio de imÃ³veis do IPTU de Recife. As anÃ¡lises cobrem:

- **Volume**: DistribuiÃ§Ã£o total de imÃ³veis por tipo, bairro, ano e construÃ§Ã£o
- **Idade**: AnÃ¡lise da distribuiÃ§Ã£o por faixas de idade de construÃ§Ã£o
- **Valor**: Bairros com maiores valores de IPTU e relaÃ§Ã£o idade Ã— valor
- **EvoluÃ§Ã£o**: Crescimento de bairros em quantidade e valor ao longo do tempo

**Resultados:**
- ğŸ“Š **12 visualizaÃ§Ãµes interativas** em formato HTML (Plotly) + PNG (alta qualidade)
- ğŸ“ˆ **20+ anÃ¡lises** detalhadas (CSV)
- ğŸ“„ **1 relatÃ³rio HTML** interativo com todas as visualizaÃ§Ãµes e tabelas

Todas as anÃ¡lises sÃ£o geradas automaticamente ao executar o pipeline e salvos em `data/gold/analyses/` e `data/gold/plots/`.

### ğŸ“ˆ AnÃ¡lises e Respostas Ã s Perguntas Principais

O pipeline realiza anÃ¡lises abrangentes que respondem Ã s perguntas principais sobre o inventÃ¡rio de imÃ³veis do IPTU:

---

#### 1. Volume: Qual o total de imÃ³veis e como o inventÃ¡rio estÃ¡ distribuÃ­do fisicamente?

**Resposta:** O dataset consolidado contÃ©m **1.637.779 imÃ³veis** totais (acumulado de 2020-2024).

**DistribuiÃ§Ã£o por Tipo de Uso:**
- AnÃ¡lise completa disponÃ­vel em: `data/gold/analyses/volume_analysis/volume_by_type.csv`
- VisualizaÃ§Ã£o interativa: [`data/gold/plots/volume_by_type.html`](data/gold/plots/volume_by_type.html)

**DistribuiÃ§Ã£o por Bairro:**
- Top 20 bairros com mais imÃ³veis: `data/gold/analyses/volume_analysis/volume_by_neighborhood.csv`
- VisualizaÃ§Ã£o interativa: [`data/gold/plots/top_neighborhoods.html`](data/gold/plots/top_neighborhoods.html)

**DistribuiÃ§Ã£o Temporal:**
- Volume por ano (2020-2024): `data/gold/analyses/volume_analysis/volume_by_year.csv`
- VisualizaÃ§Ã£o interativa: [`data/gold/plots/volume_by_year.html`](data/gold/plots/volume_by_year.html)

**DistribuiÃ§Ã£o Combinada (Ano Ã— Tipo):**
- AnÃ¡lise cruzada ano/tipo: `data/gold/analyses/volume_analysis/volume_by_year_type.csv`
- VisualizaÃ§Ã£o interativa: [`data/gold/plots/volume_by_year_type.html`](data/gold/plots/volume_by_year_type.html)

**DistribuiÃ§Ã£o por Tipo de ConstruÃ§Ã£o:**
- AnÃ¡lise: `data/gold/analyses/distribution_analysis/distribution_by_construction.csv`
- VisualizaÃ§Ã£o interativa: [`data/gold/plots/distribution_by_construction.html`](data/gold/plots/distribution_by_construction.html)

---

#### 2. Idade: Como o inventÃ¡rio estÃ¡ distribuÃ­do em termos de idade de construÃ§Ã£o?

**Resposta:** A distribuiÃ§Ã£o por faixas de idade mostra que:
- **41-50 anos**: 467.333 imÃ³veis (maior faixa)
- **21-30 anos**: 273.655 imÃ³veis
- **11-20 anos**: 231.864 imÃ³veis
- **60+ anos**: 203.572 imÃ³veis
- **31-40 anos**: 176.620 imÃ³veis
- **51-60 anos**: 174.710 imÃ³veis
- **0-10 anos**: 110.025 imÃ³veis

**AnÃ¡lise Completa:**
- DistribuiÃ§Ã£o por faixas: `data/gold/analyses/age_analysis/age_distribution_by_range.csv`
- EstatÃ­sticas: `data/gold/analyses/age_analysis/age_statistics.csv`
- DistribuiÃ§Ã£o temporal: [`data/gold/plots/temporal_distribution.html`](data/gold/plots/temporal_distribution.html)
- DistribuiÃ§Ã£o por idade: [`data/gold/plots/age_distribution.html`](data/gold/plots/age_distribution.html)

A maioria dos imÃ³veis tem entre 21-50 anos de construÃ§Ã£o, indicando um inventÃ¡rio predominantemente de meia-idade.

---

#### 3. Valor (R$): Quais os bairros com imÃ³veis mais valiosos? HÃ¡ relaÃ§Ã£o direta entre idade e valor?

**Bairros com Maior Valor MÃ©dio de IPTU:**

| Bairro | Valor MÃ©dio IPTU (R$) | Total (R$) | Qtd. ImÃ³veis |
|--------|----------------------|-----------|--------------|
| DOIS IRMAOS | 8.199,33 | 2.951.757,86 | 360 |
| MONTEIRO | 4.431,75 | 34.580.948,84 | 7.803 |
| GUABIRABA | 4.223,49 | 9.000.253,52 | 2.131 |
| JAQUEIRA | 3.854,44 | 11.320.488,43 | 2.937 |
| ILHA DO RETIRO | 3.816,16 | 18.580.887,28 | 4.869 |

**AnÃ¡lise Completa:**
- Top 20 bairros por valor mÃ©dio: `data/gold/analyses/tax_value_analysis/avg_tax_by_neighborhood_top20.csv`
- VisualizaÃ§Ã£o interativa: [`data/gold/plots/top_tax_neighborhoods.html`](data/gold/plots/top_tax_neighborhoods.html)
- TendÃªncias de valor (Boxplot): [`data/gold/plots/tax_trends.html`](data/gold/plots/tax_trends.html)

**RelaÃ§Ã£o Idade Ã— Valor:**

A anÃ¡lise mostra uma **relaÃ§Ã£o inversa interessante**:
- **0-10 anos**: Valor mÃ©dio IPTU = R$ 2.126,84 (imÃ³veis mais novos, valor mÃ©dio)
- **11-20 anos**: Valor mÃ©dio IPTU = R$ 2.991,03 (pico de valor)
- **21-30 anos**: Valor mÃ©dio IPTU = R$ 2.172,92
- **31-40 anos**: Valor mÃ©dio IPTU = R$ 1.521,58
- **41-50 anos**: Valor mÃ©dio IPTU = R$ 786,38 (maior quantidade, menor valor mÃ©dio)
- **50+ anos**: Valor mÃ©dio IPTU = R$ 1.028,19

**ConclusÃ£o:** NÃ£o hÃ¡ relaÃ§Ã£o direta simples. ImÃ³veis de **11-20 anos** tÃªm o maior valor mÃ©dio, enquanto imÃ³veis **41-50 anos** (a faixa mais numerosa) tÃªm menor valor mÃ©dio. Isso sugere que fatores alÃ©m da idade (localizaÃ§Ã£o, padrÃ£o de construÃ§Ã£o, infraestrutura) influenciam fortemente o valor.

**AnÃ¡lise Completa:**
- RelaÃ§Ã£o idade-valor: `data/gold/analyses/age_value_analysis/age_value_relationship.csv`
- VisualizaÃ§Ã£o interativa: [`data/gold/plots/age_value_relationship.html`](data/gold/plots/age_value_relationship.html)

---

#### 4. EvoluÃ§Ã£o: Quais bairros apresentam maior evoluÃ§Ã£o em nÃºmero de imÃ³veis? E em relaÃ§Ã£o a valor?

**Bairros com Maior Crescimento em Quantidade:**

A anÃ¡lise comparativa entre o primeiro e Ãºltimo ano mostra que muitos bairros apresentaram **reduÃ§Ã£o** significativa no nÃºmero de registros (possivelmente devido a consolidaÃ§Ãµes, alteraÃ§Ãµes administrativas ou melhoria na qualidade dos dados). Para identificar crescimento real, a anÃ¡lise foca em bairros que mantiveram consistÃªncia nos dados.

**Top Crescimentos:**
- AnÃ¡lise completa: `data/gold/analyses/evolution_analysis/top_growth_quantity.csv`
- AnÃ¡lise por bairro: `data/gold/analyses/evolution_analysis/neighborhood_evolution.csv`
- VisualizaÃ§Ã£o interativa: [`data/gold/plots/neighborhood_growth_quantity.html`](data/gold/plots/neighborhood_growth_quantity.html)

**Bairros com Maior Crescimento em Valor:**
- AnÃ¡lise completa: `data/gold/analyses/evolution_analysis/top_growth_value.csv`
- VisualizaÃ§Ã£o interativa: [`data/gold/plots/neighborhood_growth_value.html`](data/gold/plots/neighborhood_growth_value.html)

**TendÃªncias Anuais:**
- EstatÃ­sticas por ano: `data/gold/analyses/tax_value_analysis/tax_stats_by_year.csv`
- Valores de propriedade: `data/gold/analyses/tax_value_analysis/property_value_by_year.csv`
- VisualizaÃ§Ã£o interativa: [`data/gold/plots/tax_trends.html`](data/gold/plots/tax_trends.html)

**ObservaÃ§Ã£o:** A evoluÃ§Ã£o precisa ser analisada considerando que mudanÃ§as administrativas, consolidaÃ§Ãµes de registros e melhorias na qualidade dos dados podem afetar as comparaÃ§Ãµes ano a ano.

---

### ğŸ“Š Todas as VisualizaÃ§Ãµes DisponÃ­veis

Todas as visualizaÃ§Ãµes sÃ£o geradas automaticamente em formato HTML interativo e PNG (alta qualidade, 2x scale) e salvas em `data/gold/plots/`:

#### 1. AnÃ¡lise de Volume

**Volume por Ano** - GrÃ¡fico de barras do total de imÃ³veis por ano

[![Volume por Ano](data/gold/plots/volume_by_year.png)](data/gold/plots/volume_by_year.html)

**Volume por Tipo** - GrÃ¡fico de pizza + barras por tipo de uso

[![Volume por Tipo](data/gold/plots/volume_by_type.png)](data/gold/plots/volume_by_type.html)

**Top Bairros** - Top 20 bairros por quantidade de imÃ³veis

[![Top Bairros](data/gold/plots/top_neighborhoods.png)](data/gold/plots/top_neighborhoods.html)

**Volume Ano Ã— Tipo** - GrÃ¡fico de Ã¡rea empilhada mostrando evoluÃ§Ã£o

[![Volume Ano Ã— Tipo](data/gold/plots/volume_by_year_type.png)](data/gold/plots/volume_by_year_type.html)

**DistribuiÃ§Ã£o por ConstruÃ§Ã£o** - GrÃ¡fico de barras por tipo de construÃ§Ã£o

[![DistribuiÃ§Ã£o por ConstruÃ§Ã£o](data/gold/plots/distribution_by_construction.png)](data/gold/plots/distribution_by_construction.html)

**DistribuiÃ§Ã£o Temporal** - Timeline mostrando distribuiÃ§Ã£o ao longo do tempo

[![DistribuiÃ§Ã£o Temporal](data/gold/plots/temporal_distribution.png)](data/gold/plots/temporal_distribution.html)

#### 2. AnÃ¡lise de Valores de IPTU

**TendÃªncias de IPTU (Boxplot)** - DistribuiÃ§Ã£o de valores de IPTU por ano

[![TendÃªncias de IPTU](data/gold/plots/tax_trends.png)](data/gold/plots/tax_trends.html)

**Top Bairros por IPTU** - Top 20 bairros por valor mÃ©dio de IPTU

[![Top Bairros por IPTU](data/gold/plots/top_tax_neighborhoods.png)](data/gold/plots/top_tax_neighborhoods.html)

#### 3. AnÃ¡lise de Idade de ConstruÃ§Ã£o

**DistribuiÃ§Ã£o por Faixas de Idade** - DistribuiÃ§Ã£o de imÃ³veis por idade de construÃ§Ã£o

[![DistribuiÃ§Ã£o por Idade](data/gold/plots/age_distribution.png)](data/gold/plots/age_distribution.html)

**RelaÃ§Ã£o Idade Ã— Valor** - Valor mÃ©dio de IPTU por faixa de idade de construÃ§Ã£o

[![RelaÃ§Ã£o Idade Ã— Valor](data/gold/plots/age_value_relationship.png)](data/gold/plots/age_value_relationship.html)

#### 4. AnÃ¡lise de EvoluÃ§Ã£o de Bairros

**Crescimento em Quantidade** - Top bairros com maior crescimento em nÃºmero de imÃ³veis

[![Crescimento em Quantidade](data/gold/plots/neighborhood_growth_quantity.png)](data/gold/plots/neighborhood_growth_quantity.html)

**Crescimento em Valor** - Top bairros com maior crescimento em valor mÃ©dio de IPTU

[![Crescimento em Valor](data/gold/plots/neighborhood_growth_value.png)](data/gold/plots/neighborhood_growth_value.html)

#### ğŸ“„ RelatÃ³rio Completo

**RelatÃ³rio HTML Interativo** - Todas as visualizaÃ§Ãµes e anÃ¡lises em um Ãºnico documento
- VisualizaÃ§Ã£o: [`visualizations_report.html`](data/gold/plots/visualizations_report.html)

> ğŸ’¡ **Dica**: Clique em qualquer imagem acima para abrir a versÃ£o HTML interativa no navegador. Use zoom, hover e filtros para explorar os dados!

---

### ğŸ“‚ Estrutura Completa das AnÃ¡lises

Todas as anÃ¡lises sÃ£o salvas em `data/gold/analyses/` organizadas por categoria:

```
analyses/
â”œâ”€â”€ volume_analysis/              # AnÃ¡lise de volume
â”‚   â”œâ”€â”€ total_properties.csv
â”‚   â”œâ”€â”€ volume_by_year.csv
â”‚   â”œâ”€â”€ volume_by_type.csv
â”‚   â”œâ”€â”€ volume_by_neighborhood.csv
â”‚   â”œâ”€â”€ volume_by_year_type.csv
â”‚   â””â”€â”€ volume_by_year_neighborhood.csv
â”‚
â”œâ”€â”€ distribution_analysis/        # AnÃ¡lise de distribuiÃ§Ã£o fÃ­sica
â”‚   â”œâ”€â”€ distribution_by_type.csv
â”‚   â”œâ”€â”€ distribution_by_neighborhood_top20.csv
â”‚   â”œâ”€â”€ distribution_by_year.csv
â”‚   â”œâ”€â”€ distribution_by_construction.csv
â”‚   â””â”€â”€ top_neighborhoods_by_year.csv
â”‚
â”œâ”€â”€ tax_value_analysis/           # AnÃ¡lise de valores de IPTU
â”‚   â”œâ”€â”€ tax_stats_by_year.csv
â”‚   â”œâ”€â”€ property_value_by_year.csv
â”‚   â””â”€â”€ avg_tax_by_neighborhood_top20.csv
â”‚
â”œâ”€â”€ age_analysis/                 # AnÃ¡lise de idade de construÃ§Ã£o
â”‚   â”œâ”€â”€ age_distribution_by_range.csv
â”‚   â””â”€â”€ age_statistics.csv
â”‚
â”œâ”€â”€ age_value_analysis/           # RelaÃ§Ã£o idade-valor
â”‚   â””â”€â”€ age_value_relationship.csv
â”‚
â””â”€â”€ evolution_analysis/           # EvoluÃ§Ã£o de bairros
    â”œâ”€â”€ neighborhood_evolution.csv
    â”œâ”€â”€ top_growth_quantity.csv
    â””â”€â”€ top_growth_value.csv
```

---

## ğŸ“¤ Outputs

### Medallion Layers

| Layer | Location | Format | Description |
|-------|----------|--------|-------------|
| **Raw** | `data/raw/` | CSV/JSON | Source files |
| **Bronze** | `data/bronze/` | Delta/Parquet | Cleaned data |
| **Silver** | `data/silver/` | Delta/Parquet | Consolidated |
| **Gold** | `data/gold/` | CSV/PNG/HTML | Analytics |

### Analysis Results

`data/gold/analyses/` contÃ©m anÃ¡lises completas organizadas por categoria:

#### Volume Analysis (`volume_analysis/`)
- `total_properties.csv`: Total de imÃ³veis (1.637.779)
- `volume_by_year.csv`: Volume por ano (2020-2024)
- `volume_by_type.csv`: Volume por tipo de uso do imÃ³vel
- `volume_by_neighborhood.csv`: Volume por bairro
- `volume_by_year_type.csv`: AnÃ¡lise cruzada ano Ã— tipo
- `volume_by_year_neighborhood.csv`: AnÃ¡lise cruzada ano Ã— bairro

#### Distribution Analysis (`distribution_analysis/`)
- `distribution_by_type.csv`: DistribuiÃ§Ã£o por tipo de uso
- `distribution_by_neighborhood_top20.csv`: Top 20 bairros
- `distribution_by_year.csv`: DistribuiÃ§Ã£o temporal
- `distribution_by_construction.csv`: Por tipo de construÃ§Ã£o
- `top_neighborhoods_by_year.csv`: Top bairros por ano

#### Tax Value Analysis (`tax_value_analysis/`)
- `tax_stats_by_year.csv`: EstatÃ­sticas de IPTU por ano (mÃ©dia, mediana, min, max)
- `property_value_by_year.csv`: Valores de propriedade por ano
- `avg_tax_by_neighborhood_top20.csv`: Top 20 bairros por valor mÃ©dio de IPTU

#### Age Analysis (`age_analysis/`)
- `age_distribution_by_range.csv`: DistribuiÃ§Ã£o por faixas de idade (0-10, 11-20, etc.)
- `age_statistics.csv`: EstatÃ­sticas (mÃ©dia, mediana, min, max)

#### Age-Value Analysis (`age_value_analysis/`)
- `age_value_relationship.csv`: RelaÃ§Ã£o entre idade de construÃ§Ã£o e valor de IPTU

#### Evolution Analysis (`evolution_analysis/`)
- `neighborhood_evolution.csv`: EvoluÃ§Ã£o completa por bairro
- `top_growth_quantity.csv`: Top bairros com maior crescimento em quantidade
- `top_growth_value.csv`: Top bairros com maior crescimento em valor

### Visualizations

`data/gold/plots/` contÃ©m 12 visualizaÃ§Ãµes interativas em formato HTML (Plotly) + relatÃ³rio HTML:

#### AnÃ¡lise de Volume (6 visualizaÃ§Ãµes)
1. [`volume_by_year.html`](data/gold/plots/volume_by_year.html) - Volume de imÃ³veis por ano
2. [`volume_by_type.html`](data/gold/plots/volume_by_type.html) - DistribuiÃ§Ã£o por tipo de uso
3. [`top_neighborhoods.html`](data/gold/plots/top_neighborhoods.html) - Top 20 bairros por quantidade
4. [`volume_by_year_type.html`](data/gold/plots/volume_by_year_type.html) - EvoluÃ§Ã£o ano Ã— tipo
5. [`distribution_by_construction.html`](data/gold/plots/distribution_by_construction.html) - DistribuiÃ§Ã£o por tipo de construÃ§Ã£o
6. [`temporal_distribution.html`](data/gold/plots/temporal_distribution.html) - DistribuiÃ§Ã£o temporal

#### AnÃ¡lise de Valores de IPTU (2 visualizaÃ§Ãµes)
7. [`tax_trends.html`](data/gold/plots/tax_trends.html) - TendÃªncias de valores de IPTU (Boxplot por ano)
8. [`top_tax_neighborhoods.html`](data/gold/plots/top_tax_neighborhoods.html) - Top 20 bairros por valor de IPTU

#### AnÃ¡lise de Idade de ConstruÃ§Ã£o (2 visualizaÃ§Ãµes)
9. [`age_distribution.html`](data/gold/plots/age_distribution.html) - DistribuiÃ§Ã£o por faixas de idade de construÃ§Ã£o
10. [`age_value_relationship.html`](data/gold/plots/age_value_relationship.html) - RelaÃ§Ã£o entre idade de construÃ§Ã£o e valor de IPTU

#### AnÃ¡lise de EvoluÃ§Ã£o de Bairros (2 visualizaÃ§Ãµes)
11. [`neighborhood_growth_quantity.html`](data/gold/plots/neighborhood_growth_quantity.html) - Crescimento em nÃºmero de imÃ³veis por bairro
12. [`neighborhood_growth_value.html`](data/gold/plots/neighborhood_growth_value.html) - Crescimento em valor mÃ©dio de IPTU por bairro

#### RelatÃ³rio HTML
13. [`visualizations_report.html`](data/gold/plots/visualizations_report.html) - RelatÃ³rio HTML interativo com todas as visualizaÃ§Ãµes e tabelas detalhadas

> ğŸ’¡ **Nota**: Todas as visualizaÃ§Ãµes sÃ£o geradas em formato HTML interativo usando Plotly. Abra os arquivos no navegador para explorar os dados com zoom, hover e filtros interativos.

### Legacy Outputs

`outputs/`:
- `validation_report.csv`: Validation summary
- `validation_errors.csv`: Detailed errors
- `medallion_validation_report.json`: Layer validation

### Catalog

`data/catalog/`:
- `data_catalog.json`: Human-readable metadata
- `data_catalog.parquet`: Queryable catalog
- `data_catalog_delta/`: Delta table catalog

---

## ğŸ”¬ Advanced Features

### Delta Lake Features

1. **ACID Transactions**: Ensure data integrity
2. **Schema Evolution**: Add/rename columns without rewriting
3. **Column Mapping**: Handle special characters in column names
4. **Time Travel**: Query historical versions
5. **Partitioning**: Partition by year for performance

### PyDeequ Integration

Automated data quality checks:
- Completeness checks
- Anomaly detection
- Column profiling
- Constraint checks

### Catalog System

Centralized metadata tracking:
- File discovery timestamp
- MD5 checksum
- Processing status
- Schema snapshots
- Row/column counts

### Incremental Processing

Add new years without reprocessing:
1. Checks existing years in Silver layer
2. Only processes new years
3. Appends to existing data
4. Updates analyses

### Export Script

`export_refined_dataset.py`:
- Removes duplicates
- Filters metadata columns
- Normalizes timestamps
- Creates single Parquet file

---

## ğŸ¯ Next Steps

Future enhancements:
- [ ] Unit test coverage
- [ ] CI/CD pipeline
- [ ] Web dashboard deployment
- [ ] Database integration (PostgreSQL/MongoDB)
- [ ] Real-time streaming support (Kafka)
- [ ] ML model integration
- [ ] Cost optimization for Spark

---

**Built with â¤ï¸ for the Neuro Tech Challenge**
